{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "- MAI XUÂN BÁCH\n",
        "- 11200489\n",
        "- DSEB 62\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ylIwydeistT"
      },
      "id": "7ylIwydeistT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTIONS**\n",
        "\n",
        "Cho 2 pretrained model trên 2 dataset CIFAR-10 và MNIST, finetune trên dataset mới FashionMNIST (có trong thư viện torchvision).\n",
        "\n",
        "- Data augmentation: normalize ảnh từ scale [0, 255] về [-1,1], sử dụng ít nhất 2 trong số các transformations dưới đây cho dataset: Random resized, Center cropping, Random vertical flipping, Random horizontal flipping, Các loại transformation khác có thể tham khảo ở đây https://pytorch.org/vision/master/transforms.html\n",
        "\n",
        "- Fine-tuning: Cho mô hình MiniVGG như dưới, hãy load 2 pretrained models vào model MiniVGG ở dưới. Freeze self.features và train lớp cuối (self.classifier) của 2 pretrained models trên dataset FashionMNIST. Sau đó, train model MiniVGG from scratch trên tập FashionMNIST.\n",
        "\n",
        "Với 3 models, train 5 epochs và báo cáo accuracy trên tập test của 3 models Mô hình nào có accuracy cao nhất và tại sao? Nếu train với nhiều epochs hơn thì accuracy của 3 models có giống nhau không?\n",
        "\n",
        "- Feature extractor: Với model tương tự như homework 2, dùng get_graph_node_names() và create_feature_extractor từ thư viện torchvision.models.feature_extraction để in ra tên layer và weight của layer tương ứng"
      ],
      "metadata": {
        "id": "L19xl-iCiuDO"
      },
      "id": "L19xl-iCiuDO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "KUTZTajXjBTT"
      },
      "id": "KUTZTajXjBTT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8a11e6",
      "metadata": {
        "id": "dd8a11e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ffb56e",
      "metadata": {
        "id": "69ffb56e"
      },
      "source": [
        "# 1. Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84092cd",
      "metadata": {
        "id": "a84092cd"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize to [-1, 1]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e8aef8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e8aef8",
        "outputId": "03fca964-62f0-484c-f7e4-3affffd2c23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11146575.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 201686.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3742477.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5963070.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "train_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=64, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=64, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949c93ed",
      "metadata": {
        "id": "949c93ed"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3aef601",
      "metadata": {
        "id": "a3aef601"
      },
      "outputs": [],
      "source": [
        "#cifar_10_pre_model = models.vgg11(pretrained = True)\n",
        "#cifar_10_pre_model.load_state_dict(torch.load(\"cifar10_mini_vgg.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076575",
      "metadata": {
        "id": "58076575"
      },
      "outputs": [],
      "source": [
        "class MiniVGG(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(MiniVGG, self).__init__()\n",
        "        self.features = nn.Sequential(nn.Conv2d(1,64,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "                                      nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(128,128,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "                                      nn.Conv2d(128,256,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Linear(256*3*3,10)\n",
        "        nn.init.normal_(self.classifier.weight,0, 0.01)\n",
        "        nn.init.constant_(self.classifier.bias,0)\n",
        "\n",
        "\n",
        "    def forward(self,x,):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Finetuning"
      ],
      "metadata": {
        "id": "sBiAdzWrjSdm"
      },
      "id": "sBiAdzWrjSdm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b058e76",
      "metadata": {
        "id": "6b058e76"
      },
      "outputs": [],
      "source": [
        "model = MiniVGG().to(device)\n",
        "model.load_state_dict(torch.load(\"cifar10_mini_vgg.pth\", map_location=torch.device('cpu')))\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c796921",
      "metadata": {
        "id": "6c796921"
      },
      "outputs": [],
      "source": [
        "model_2 = MiniVGG().to(device)\n",
        "model_2.load_state_dict(torch.load('mnist_mini_vgg.pth',map_location=torch.device('cpu')))\n",
        "for param in model_2.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model_2.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c395ca5",
      "metadata": {
        "id": "6c395ca5"
      },
      "outputs": [],
      "source": [
        "model_3 = MiniVGG().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1501dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1501dc",
        "outputId": "19cae39e-a4ea-43bf-9d26-78bfbe8e9e5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27932db4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27932db4",
        "outputId": "e2d69e24-b4fb-4bd4-e9a2-9fb6688eb219"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e2e149c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e2e149c",
        "outputId": "8e14aa4b-e950-4401-ef81-6494f35af25c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model_3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "moment = 0.9"
      ],
      "metadata": {
        "id": "fnDJKbEOzGEC"
      },
      "id": "fnDJKbEOzGEC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039b2355",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "039b2355",
        "outputId": "5e787913-a8b5-41d5-8c0d-3e5035e7e448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5, Step: 100/938, Loss: 0.8716\n",
            "Epoch: 1/5, Step: 200/938, Loss: 0.8412\n",
            "Epoch: 1/5, Step: 300/938, Loss: 0.8546\n",
            "Epoch: 1/5, Step: 400/938, Loss: 0.4254\n",
            "Epoch: 1/5, Step: 500/938, Loss: 0.6400\n",
            "Epoch: 1/5, Step: 600/938, Loss: 0.3884\n",
            "Epoch: 1/5, Step: 700/938, Loss: 0.3127\n",
            "Epoch: 1/5, Step: 800/938, Loss: 0.5258\n",
            "Epoch: 1/5, Step: 900/938, Loss: 0.4565\n",
            "Epoch: 2/5, Step: 100/938, Loss: 0.6036\n",
            "Epoch: 2/5, Step: 200/938, Loss: 0.3947\n",
            "Epoch: 2/5, Step: 300/938, Loss: 0.3940\n",
            "Epoch: 2/5, Step: 400/938, Loss: 0.7728\n",
            "Epoch: 2/5, Step: 500/938, Loss: 0.4083\n",
            "Epoch: 2/5, Step: 600/938, Loss: 0.2919\n",
            "Epoch: 2/5, Step: 700/938, Loss: 0.4520\n",
            "Epoch: 2/5, Step: 800/938, Loss: 0.2921\n",
            "Epoch: 2/5, Step: 900/938, Loss: 0.2435\n",
            "Epoch: 3/5, Step: 100/938, Loss: 0.5518\n",
            "Epoch: 3/5, Step: 200/938, Loss: 0.3183\n",
            "Epoch: 3/5, Step: 300/938, Loss: 0.1869\n",
            "Epoch: 3/5, Step: 400/938, Loss: 0.3964\n",
            "Epoch: 3/5, Step: 500/938, Loss: 0.3415\n",
            "Epoch: 3/5, Step: 600/938, Loss: 0.4410\n",
            "Epoch: 3/5, Step: 700/938, Loss: 0.6094\n",
            "Epoch: 3/5, Step: 800/938, Loss: 0.3503\n",
            "Epoch: 3/5, Step: 900/938, Loss: 0.4189\n",
            "Epoch: 4/5, Step: 100/938, Loss: 0.2952\n",
            "Epoch: 4/5, Step: 200/938, Loss: 0.1929\n",
            "Epoch: 4/5, Step: 300/938, Loss: 0.2739\n",
            "Epoch: 4/5, Step: 400/938, Loss: 0.3069\n",
            "Epoch: 4/5, Step: 500/938, Loss: 0.2160\n",
            "Epoch: 4/5, Step: 600/938, Loss: 0.4266\n",
            "Epoch: 4/5, Step: 700/938, Loss: 0.1338\n",
            "Epoch: 4/5, Step: 800/938, Loss: 0.4173\n",
            "Epoch: 4/5, Step: 900/938, Loss: 0.2055\n",
            "Epoch: 5/5, Step: 100/938, Loss: 0.2037\n",
            "Epoch: 5/5, Step: 200/938, Loss: 0.1737\n",
            "Epoch: 5/5, Step: 300/938, Loss: 0.3250\n",
            "Epoch: 5/5, Step: 400/938, Loss: 0.3146\n",
            "Epoch: 5/5, Step: 500/938, Loss: 0.2609\n",
            "Epoch: 5/5, Step: 600/938, Loss: 0.1476\n",
            "Epoch: 5/5, Step: 700/938, Loss: 0.1057\n",
            "Epoch: 5/5, Step: 800/938, Loss: 0.3693\n",
            "Epoch: 5/5, Step: 900/938, Loss: 0.4291\n",
            "Learning Rate: 0.001, Accuracy: 0.8868\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=moment)\n",
        "\n",
        "# Set the batch size of the model\n",
        "#model.batch_size = 3\n",
        "\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        #loss.requires_grad = True\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #loss.requires_grad = True\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Epoch: {}/5, Step: {}/{}, Loss: {:.4f}\".format(\n",
        "                epoch + 1, i + 1, len(train_loader), loss.item()\n",
        "            ))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = images.size(0)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f'Learning Rate: {lr}, Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d290bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53d290bc",
        "outputId": "c43190f8-66b3-4baa-d691-c48cdab62e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5, Step: 100/938, Loss: 1.4329\n",
            "Epoch: 1/5, Step: 200/938, Loss: 0.6004\n",
            "Epoch: 1/5, Step: 300/938, Loss: 0.3417\n",
            "Epoch: 1/5, Step: 400/938, Loss: 0.4598\n",
            "Epoch: 1/5, Step: 500/938, Loss: 0.5689\n",
            "Epoch: 1/5, Step: 600/938, Loss: 0.6485\n",
            "Epoch: 1/5, Step: 700/938, Loss: 0.3370\n",
            "Epoch: 1/5, Step: 800/938, Loss: 0.3816\n",
            "Epoch: 1/5, Step: 900/938, Loss: 0.5827\n",
            "Epoch: 2/5, Step: 100/938, Loss: 0.3452\n",
            "Epoch: 2/5, Step: 200/938, Loss: 0.6238\n",
            "Epoch: 2/5, Step: 300/938, Loss: 0.4112\n",
            "Epoch: 2/5, Step: 400/938, Loss: 0.4004\n",
            "Epoch: 2/5, Step: 500/938, Loss: 0.3255\n",
            "Epoch: 2/5, Step: 600/938, Loss: 0.4075\n",
            "Epoch: 2/5, Step: 700/938, Loss: 0.3818\n",
            "Epoch: 2/5, Step: 800/938, Loss: 0.6509\n",
            "Epoch: 2/5, Step: 900/938, Loss: 0.4844\n",
            "Epoch: 3/5, Step: 100/938, Loss: 0.5788\n",
            "Epoch: 3/5, Step: 200/938, Loss: 0.4892\n",
            "Epoch: 3/5, Step: 300/938, Loss: 0.5256\n",
            "Epoch: 3/5, Step: 400/938, Loss: 0.6352\n",
            "Epoch: 3/5, Step: 500/938, Loss: 0.2651\n",
            "Epoch: 3/5, Step: 600/938, Loss: 0.4807\n",
            "Epoch: 3/5, Step: 700/938, Loss: 0.4662\n",
            "Epoch: 3/5, Step: 800/938, Loss: 0.3779\n",
            "Epoch: 3/5, Step: 900/938, Loss: 0.4967\n",
            "Epoch: 4/5, Step: 100/938, Loss: 0.2161\n",
            "Epoch: 4/5, Step: 200/938, Loss: 0.6110\n",
            "Epoch: 4/5, Step: 300/938, Loss: 0.4611\n",
            "Epoch: 4/5, Step: 400/938, Loss: 0.3607\n",
            "Epoch: 4/5, Step: 500/938, Loss: 0.4740\n",
            "Epoch: 4/5, Step: 600/938, Loss: 0.3539\n",
            "Epoch: 4/5, Step: 700/938, Loss: 0.2868\n",
            "Epoch: 4/5, Step: 800/938, Loss: 0.3229\n",
            "Epoch: 4/5, Step: 900/938, Loss: 0.3404\n",
            "Epoch: 5/5, Step: 100/938, Loss: 0.4707\n",
            "Epoch: 5/5, Step: 200/938, Loss: 0.3831\n",
            "Epoch: 5/5, Step: 300/938, Loss: 0.2792\n",
            "Epoch: 5/5, Step: 400/938, Loss: 0.5393\n",
            "Epoch: 5/5, Step: 500/938, Loss: 0.4251\n",
            "Epoch: 5/5, Step: 600/938, Loss: 0.4197\n",
            "Epoch: 5/5, Step: 700/938, Loss: 0.5148\n",
            "Epoch: 5/5, Step: 800/938, Loss: 0.5970\n",
            "Epoch: 5/5, Step: 900/938, Loss: 0.3233\n",
            "Learning Rate: 0.001, Accuracy: 0.8575\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr=lr, momentum=moment)\n",
        "\n",
        "# Set the batch size of the model\n",
        "model_2.batch_size = 3\n",
        "\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_2(images)\n",
        "        #loss.requires_grad = True\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        # loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        #loss.requires_grad = True\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Epoch: {}/5, Step: {}/{}, Loss: {:.4f}\".format(\n",
        "                epoch + 1, i + 1, len(train_loader), loss.item()\n",
        "            ))\n",
        "\n",
        "\n",
        "model_2.eval()\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = images.size(0)\n",
        "        outputs = model_2(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f'Learning Rate: {lr}, Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc92d2ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc92d2ac",
        "outputId": "51cd8ec2-4598-490b-bc1e-d0c0b7116e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5, Step: 100/938, Loss: 2.3013\n",
            "Epoch: 1/5, Step: 200/938, Loss: 2.2990\n",
            "Epoch: 1/5, Step: 300/938, Loss: 2.2989\n",
            "Epoch: 1/5, Step: 400/938, Loss: 2.2939\n",
            "Epoch: 1/5, Step: 500/938, Loss: 2.2867\n",
            "Epoch: 1/5, Step: 600/938, Loss: 2.1318\n",
            "Epoch: 1/5, Step: 700/938, Loss: 1.2196\n",
            "Epoch: 1/5, Step: 800/938, Loss: 0.8483\n",
            "Epoch: 1/5, Step: 900/938, Loss: 0.7755\n",
            "Epoch: 2/5, Step: 100/938, Loss: 1.0395\n",
            "Epoch: 2/5, Step: 200/938, Loss: 0.7631\n",
            "Epoch: 2/5, Step: 300/938, Loss: 0.6003\n",
            "Epoch: 2/5, Step: 400/938, Loss: 0.6598\n",
            "Epoch: 2/5, Step: 500/938, Loss: 0.5493\n",
            "Epoch: 2/5, Step: 600/938, Loss: 0.6259\n",
            "Epoch: 2/5, Step: 700/938, Loss: 0.4880\n",
            "Epoch: 2/5, Step: 800/938, Loss: 0.6186\n",
            "Epoch: 2/5, Step: 900/938, Loss: 0.5061\n",
            "Epoch: 3/5, Step: 100/938, Loss: 0.7053\n",
            "Epoch: 3/5, Step: 200/938, Loss: 0.5312\n",
            "Epoch: 3/5, Step: 300/938, Loss: 0.6016\n",
            "Epoch: 3/5, Step: 400/938, Loss: 0.5265\n",
            "Epoch: 3/5, Step: 500/938, Loss: 0.6219\n",
            "Epoch: 3/5, Step: 600/938, Loss: 0.3862\n",
            "Epoch: 3/5, Step: 700/938, Loss: 0.4990\n",
            "Epoch: 3/5, Step: 800/938, Loss: 0.3072\n",
            "Epoch: 3/5, Step: 900/938, Loss: 0.3873\n",
            "Epoch: 4/5, Step: 100/938, Loss: 0.3336\n",
            "Epoch: 4/5, Step: 200/938, Loss: 0.3489\n",
            "Epoch: 4/5, Step: 300/938, Loss: 0.5711\n",
            "Epoch: 4/5, Step: 400/938, Loss: 0.4678\n",
            "Epoch: 4/5, Step: 500/938, Loss: 0.5688\n",
            "Epoch: 4/5, Step: 600/938, Loss: 0.4135\n",
            "Epoch: 4/5, Step: 700/938, Loss: 0.5543\n",
            "Epoch: 4/5, Step: 800/938, Loss: 0.3465\n",
            "Epoch: 4/5, Step: 900/938, Loss: 0.4904\n",
            "Epoch: 5/5, Step: 100/938, Loss: 0.2339\n",
            "Epoch: 5/5, Step: 200/938, Loss: 0.4120\n",
            "Epoch: 5/5, Step: 300/938, Loss: 0.3150\n",
            "Epoch: 5/5, Step: 400/938, Loss: 0.3936\n",
            "Epoch: 5/5, Step: 500/938, Loss: 0.5334\n",
            "Epoch: 5/5, Step: 600/938, Loss: 0.2367\n",
            "Epoch: 5/5, Step: 700/938, Loss: 0.2550\n",
            "Epoch: 5/5, Step: 800/938, Loss: 0.4377\n",
            "Epoch: 5/5, Step: 900/938, Loss: 0.2919\n",
            "Learning Rate: 0.001, Accuracy: 0.8477\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_3.parameters(), lr=lr, momentum=moment)\n",
        "\n",
        "\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_3(images)\n",
        "        #loss.requires_grad = True\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        # loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        #loss.requires_grad = True\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\"Epoch: {}/5, Step: {}/{}, Loss: {:.4f}\".format(\n",
        "                epoch + 1, i + 1, len(train_loader), loss.item()\n",
        "            ))\n",
        "\n",
        "model_3.eval()\n",
        "with torch.no_grad():\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = images.size(0)\n",
        "        outputs = model_3(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f'Learning Rate: {lr}, Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình nào có accuracy cao nhất là: **Mô hình lấy pretrained trên cifar-10**.\n",
        "\n",
        "Lí do: Dataset CIFAR có nhiều feature gần giống với dataset FashionMNIST hơn so với dataset MNIST.\n",
        "\n",
        "Nếu train với nhiều epochs hơn thì accuracy của 3 models có giống nhau không?\n",
        "\n",
        "Nếu train thêm thì model MiniVGG train from scratch sẽ tốt hơn 2 model pretrain vì các layer sẽ fit được với FashionMNIST dataset tốt hơn. 2 model pretrain (các layer đã bị freeze) do vậy nếu train thêm nữa thì layer của model cũng sẽ không học được thêm"
      ],
      "metadata": {
        "id": "uvV-lQe7kw_E"
      },
      "id": "uvV-lQe7kw_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature Extraction"
      ],
      "metadata": {
        "id": "tZIWBnzJjZA7"
      },
      "id": "tZIWBnzJjZA7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2582c3",
      "metadata": {
        "id": "7b2582c3"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "train_nodes, eval_nodes = get_graph_node_names(model_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4a1383",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4a1383",
        "outputId": "dc519896-4938-4ff3-ea52-601b69b15787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x',\n",
              " 'features.0',\n",
              " 'features.1',\n",
              " 'features.2',\n",
              " 'features.3',\n",
              " 'features.4',\n",
              " 'features.5',\n",
              " 'features.6',\n",
              " 'features.7',\n",
              " 'features.8',\n",
              " 'features.9',\n",
              " 'features.10',\n",
              " 'features.11',\n",
              " 'features.12',\n",
              " 'features.13',\n",
              " 'features.14',\n",
              " 'flatten',\n",
              " 'classifier']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_nodes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_feature_extractor(model_3, train_return_nodes= train_nodes, eval_return_nodes= eval_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnznFNcAj_KO",
        "outputId": "bfe85f89-df4f-40c2-d7f6-8b9955896aa4"
      },
      "id": "lnznFNcAj_KO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Module(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.features[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyzKsjZDkAk2",
        "outputId": "d71ce2e2-87fc-49bd-ccb2-ce263e777be8"
      },
      "id": "GyzKsjZDkAk2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-2.8759e-01,  2.0110e-01,  2.0866e-01],\n",
              "          [-1.4713e-02, -2.0285e-02, -2.5287e-01],\n",
              "          [-1.7327e-01,  1.1902e-01,  3.2581e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1258e-01,  6.7882e-02, -1.8877e-01],\n",
              "          [-3.5911e-01,  9.1008e-02, -1.3706e-01],\n",
              "          [-2.4694e-01, -3.7895e-01, -3.0658e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.2548e-01,  2.5163e-01,  1.6485e-01],\n",
              "          [-2.3129e-01,  1.2172e-02, -2.8688e-01],\n",
              "          [-7.2736e-02, -5.9601e-03,  3.1775e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.1088e-02,  2.5738e-01, -3.3810e-02],\n",
              "          [-1.4852e-01, -1.7919e-01, -2.0031e-01],\n",
              "          [-1.7278e-01, -1.2197e-01, -2.4061e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.7563e-01,  1.8458e-01,  2.1452e-01],\n",
              "          [ 2.7147e-02,  3.2068e-01, -1.4611e-01],\n",
              "          [ 2.9314e-01, -2.1236e-01, -3.1851e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.4604e-01,  6.9329e-02, -1.1402e-01],\n",
              "          [ 2.7333e-01, -2.7895e-01,  1.3624e-01],\n",
              "          [-2.7887e-01,  6.5921e-02, -3.3683e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.9302e-02, -1.8237e-01,  1.7737e-01],\n",
              "          [ 2.5987e-01,  2.1684e-01, -1.7306e-01],\n",
              "          [-1.8961e-01, -1.1318e-01,  3.0904e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.9313e-01,  4.7021e-02,  8.9225e-02],\n",
              "          [-3.0759e-01, -3.0886e-01,  6.0682e-02],\n",
              "          [ 2.0929e-01, -5.7518e-02, -2.4653e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6978e-01, -2.0594e-01,  3.3071e-01],\n",
              "          [-4.7778e-02, -2.0471e-01,  2.1928e-01],\n",
              "          [ 3.2840e-01, -1.3580e-01, -2.1692e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.5298e-02, -3.9382e-01, -2.6880e-01],\n",
              "          [-2.8197e-01, -2.7463e-01, -3.9047e-01],\n",
              "          [-1.5335e-01, -3.4210e-01, -3.0444e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.8696e-01,  2.5034e-01,  2.6828e-01],\n",
              "          [-2.9629e-04,  1.5624e-02,  1.6748e-01],\n",
              "          [ 3.1935e-01,  7.3295e-02,  3.1140e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.1220e-01,  1.6663e-01,  3.2511e-01],\n",
              "          [ 1.6291e-02, -3.4856e-02, -9.7212e-02],\n",
              "          [ 6.9502e-02, -2.3743e-01, -1.3822e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5505e-01,  6.6496e-02, -1.6354e-01],\n",
              "          [-2.2607e-01, -3.2887e-01,  2.1767e-01],\n",
              "          [ 5.7645e-04, -9.2279e-02, -4.3872e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.9502e-01, -2.7757e-01,  3.1025e-01],\n",
              "          [-1.4795e-01, -1.9222e-01, -2.1882e-01],\n",
              "          [ 1.7349e-01,  1.6736e-01,  3.1358e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.6707e-02,  9.6368e-02, -2.9161e-01],\n",
              "          [ 5.6368e-02, -3.0226e-01,  2.4837e-01],\n",
              "          [-2.2565e-01,  3.9163e-03,  3.1256e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.3597e-01, -1.7534e-01, -3.3395e-01],\n",
              "          [ 7.9625e-02, -1.5893e-01,  2.5699e-01],\n",
              "          [-2.3619e-01,  8.6607e-02, -5.7588e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.1282e-01,  1.5207e-01,  1.0186e-01],\n",
              "          [ 1.2395e-01, -1.9902e-01,  3.1994e-01],\n",
              "          [ 2.9913e-01,  1.0506e-01,  2.0205e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.3641e-01,  7.5338e-02,  6.4422e-02],\n",
              "          [-2.3369e-02, -4.2945e-02, -1.4422e-01],\n",
              "          [ 5.4674e-02,  3.2243e-01, -2.0198e-01]]],\n",
              "\n",
              "\n",
              "        [[[-9.4554e-02, -3.3218e-02, -1.3483e-01],\n",
              "          [-1.6681e-01,  2.4824e-01,  2.2036e-02],\n",
              "          [-3.1350e-02, -3.2337e-01, -2.5937e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.5942e-01, -3.4569e-01, -2.2974e-02],\n",
              "          [ 2.1599e-01, -2.6337e-01,  6.3733e-02],\n",
              "          [-3.3608e-02,  3.0585e-01,  1.1824e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4202e-01,  2.4480e-01, -2.8264e-01],\n",
              "          [ 2.7572e-01,  1.3857e-01,  9.6803e-03],\n",
              "          [-2.7851e-01,  1.4067e-01, -3.3384e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.3145e-02, -3.0041e-03, -5.4166e-02],\n",
              "          [-2.4831e-01, -2.1119e-01,  2.7942e-01],\n",
              "          [ 2.4700e-01, -2.8330e-01, -1.6634e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.2491e-01,  2.2936e-01,  2.5179e-01],\n",
              "          [-1.1707e-01, -2.5783e-01,  1.0368e-02],\n",
              "          [ 1.5376e-01, -7.5934e-02,  2.4112e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.0843e-01,  1.1332e-01,  1.2803e-01],\n",
              "          [ 2.1590e-03, -3.6049e-01,  6.4275e-02],\n",
              "          [ 1.5577e-01, -2.0662e-01, -1.3176e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5387e-01, -4.5338e-02, -7.3363e-03],\n",
              "          [-2.3269e-01, -9.0205e-03,  2.4270e-01],\n",
              "          [-7.1785e-02, -1.4781e-01, -2.9657e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.9538e-02, -2.5510e-01, -8.7785e-02],\n",
              "          [ 1.8883e-01, -1.9483e-01, -3.3534e-01],\n",
              "          [ 2.4734e-01,  2.4458e-01,  1.9188e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.3969e-01,  6.6383e-03,  1.7845e-01],\n",
              "          [ 2.3369e-01,  2.2291e-01,  1.2109e-01],\n",
              "          [ 3.3659e-01, -1.8924e-01, -3.0708e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.7729e-01, -6.7852e-02, -1.4388e-01],\n",
              "          [-9.3868e-02, -1.5881e-01, -2.0704e-01],\n",
              "          [-4.2413e-02, -1.8197e-01,  2.8006e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.1360e-01,  1.0756e-01,  3.1073e-01],\n",
              "          [-1.2078e-01, -8.7181e-02,  2.4590e-01],\n",
              "          [-3.1121e-01, -2.2860e-01, -3.4926e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.7841e-01, -2.9133e-01,  2.0568e-01],\n",
              "          [ 2.4414e-01, -1.0342e-01, -1.6020e-01],\n",
              "          [-2.1843e-01, -2.8337e-03, -4.3020e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 2.4363e-01, -2.9216e-01,  2.0019e-01],\n",
              "          [ 1.9533e-01,  1.4714e-01,  2.2071e-02],\n",
              "          [-3.2797e-01, -4.7775e-02, -1.9267e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.0780e-02,  6.0287e-02, -2.2397e-01],\n",
              "          [ 2.8122e-02, -2.5564e-01,  1.4025e-01],\n",
              "          [-1.5626e-01,  3.1152e-01, -1.1443e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.6497e-01, -3.5825e-03,  1.6450e-01],\n",
              "          [-2.0304e-01, -1.8903e-01, -2.5833e-01],\n",
              "          [ 2.0309e-01, -3.1845e-01,  1.8500e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.2747e-01,  1.5824e-01,  1.3683e-02],\n",
              "          [ 1.0875e-01, -3.0210e-01, -1.7194e-01],\n",
              "          [-8.0820e-02, -1.7352e-01, -1.7562e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5256e-01, -2.1102e-01,  1.2047e-01],\n",
              "          [ 2.1921e-01, -1.3348e-01, -1.0311e-01],\n",
              "          [-2.1794e-01,  2.3418e-01, -8.7613e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9855e-01,  1.0018e-01,  2.5570e-02],\n",
              "          [ 2.8816e-01, -4.4116e-02, -2.5243e-01],\n",
              "          [-1.5392e-01,  2.8391e-01,  1.9483e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.2544e-01,  2.2565e-01,  3.3903e-02],\n",
              "          [ 2.3035e-01,  1.8031e-01, -6.3698e-02],\n",
              "          [ 2.9229e-01, -1.6025e-01, -1.1709e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.2543e-01, -3.0176e-01,  5.1443e-02],\n",
              "          [ 1.0455e-01,  1.2239e-01,  1.1527e-01],\n",
              "          [ 1.5688e-01, -1.4303e-01, -3.1092e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.9632e-02,  1.5220e-01, -3.2384e-02],\n",
              "          [ 2.9419e-01,  1.4130e-01,  2.1896e-02],\n",
              "          [-7.7863e-02, -2.4662e-02, -7.9652e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 1.9561e-01, -1.8256e-01, -1.9599e-01],\n",
              "          [ 2.5306e-01,  2.0418e-01,  2.4475e-01],\n",
              "          [ 3.8558e-02, -2.0473e-01,  1.3254e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.2987e-01, -3.1626e-01,  1.3375e-01],\n",
              "          [ 1.5553e-01,  4.6979e-02,  1.4305e-01],\n",
              "          [-8.2546e-02, -1.5295e-01,  3.1402e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.6637e-01,  6.6127e-02,  3.5235e-02],\n",
              "          [-1.1075e-01, -3.0950e-01, -2.9522e-01],\n",
              "          [ 8.5233e-02,  3.0069e-01, -3.5668e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.7348e-01, -2.5426e-01,  2.8548e-01],\n",
              "          [-9.0309e-02, -1.9525e-01, -1.1071e-01],\n",
              "          [-2.9868e-01,  8.9589e-02, -6.9740e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.8896e-01, -2.1234e-01,  2.2213e-01],\n",
              "          [ 1.4423e-02, -2.4082e-01,  2.1834e-01],\n",
              "          [ 2.0032e-02, -4.0431e-02,  3.9542e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 7.2815e-02,  1.0243e-01,  3.1632e-01],\n",
              "          [ 3.0644e-01,  1.5384e-02,  1.6437e-01],\n",
              "          [ 8.2129e-02, -1.7087e-01, -3.4915e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.6768e-01, -3.9429e-01,  2.6980e-01],\n",
              "          [-2.8564e-01, -2.3550e-01, -5.2378e-02],\n",
              "          [ 4.9394e-02, -2.4959e-01, -1.8396e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.5593e-01, -2.1225e-01,  2.4520e-03],\n",
              "          [-2.4798e-01, -1.3187e-01,  1.1588e-01],\n",
              "          [-2.4016e-01, -3.1420e-01,  2.6492e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.7202e-02, -4.1382e-02,  2.8406e-01],\n",
              "          [-1.4726e-01, -1.8305e-02,  2.1421e-01],\n",
              "          [ 9.6880e-02,  2.3129e-01, -2.8129e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.2201e-01,  1.1309e-01, -3.0584e-01],\n",
              "          [ 2.7653e-01,  2.2034e-01,  2.9106e-01],\n",
              "          [-7.3418e-02, -1.0096e-01,  7.7029e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 5.8230e-02, -1.9404e-01,  6.2978e-02],\n",
              "          [ 2.9742e-01,  4.5948e-02,  2.5681e-01],\n",
              "          [ 4.8875e-02, -9.7402e-02, -2.2395e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.6317e-01,  3.2552e-02, -5.1613e-02],\n",
              "          [-1.5785e-01, -3.6120e-02, -1.9415e-02],\n",
              "          [-2.6698e-01, -1.0674e-01,  3.8932e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.3608e-01,  3.6177e-02,  3.0017e-01],\n",
              "          [-2.8950e-01,  1.5164e-01,  2.1436e-01],\n",
              "          [ 2.5128e-01, -2.0502e-01,  3.0515e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6046e-01,  2.9912e-01,  1.7264e-01],\n",
              "          [-8.8887e-02, -2.4598e-01,  9.5874e-02],\n",
              "          [-5.4639e-02,  1.5668e-01, -1.9736e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3966e-01,  2.9769e-02,  1.4920e-01],\n",
              "          [-3.1666e-02,  7.0724e-02, -2.5297e-01],\n",
              "          [ 1.1833e-01, -2.0151e-01, -3.1737e-01]]],\n",
              "\n",
              "\n",
              "        [[[-7.7623e-02,  1.5322e-01, -1.5622e-01],\n",
              "          [-8.7957e-02, -1.1631e-01, -1.3809e-01],\n",
              "          [-1.3676e-01, -2.1610e-01,  2.7426e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1538e-01,  1.6875e-01, -2.7721e-01],\n",
              "          [ 1.5403e-01, -9.5822e-03, -8.0904e-02],\n",
              "          [ 1.6391e-01,  3.0285e-01,  2.6148e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.0363e-01, -3.1906e-02, -2.3219e-01],\n",
              "          [ 3.1412e-01,  9.6368e-02,  1.5551e-01],\n",
              "          [ 3.3289e-01,  1.8032e-03,  3.2020e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 8.5053e-02,  1.0672e-01,  3.2172e-01],\n",
              "          [ 1.3951e-01,  1.0411e-01, -2.5623e-01],\n",
              "          [ 3.3723e-01,  2.5875e-01, -1.3236e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5468e-01,  1.0405e-01, -7.2423e-02],\n",
              "          [-1.0406e-01,  3.5691e-02, -1.3538e-02],\n",
              "          [ 2.6040e-01, -4.4807e-02,  6.1715e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 7.2364e-02,  2.1937e-01,  2.2692e-01],\n",
              "          [ 3.1713e-03,  1.5158e-01, -2.0289e-01],\n",
              "          [ 1.8515e-01,  2.5251e-01, -1.2877e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.6371e-01, -1.4746e-01,  1.7966e-01],\n",
              "          [-1.2344e-01, -1.1664e-01,  1.6010e-01],\n",
              "          [ 3.1743e-01, -9.2118e-02, -1.1717e-01]]],\n",
              "\n",
              "\n",
              "        [[[-7.4374e-02,  4.0180e-02,  1.6025e-02],\n",
              "          [ 1.7957e-01,  3.2649e-01, -2.5259e-01],\n",
              "          [-1.6528e-01,  4.7288e-02, -1.1230e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.0046e-01, -2.5669e-01, -1.3040e-01],\n",
              "          [ 1.5592e-01,  1.3054e-01, -2.9335e-01],\n",
              "          [-2.1021e-01,  2.8159e-01,  1.5725e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.8400e-02, -5.6051e-02, -9.3729e-02],\n",
              "          [-3.1063e-01, -5.8074e-02, -2.1783e-01],\n",
              "          [-6.5971e-02,  8.2329e-02, -2.1487e-01]]]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}